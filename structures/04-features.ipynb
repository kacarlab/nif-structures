{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "upstream = ['01-uniform-files']\n",
    "product = None\n",
    "input = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import networkx as nx\n",
    "import io\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = pd.read_csv(upstream['01-uniform-files']['data'], index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chain_sasa(x):\n",
    "    buried = subprocess.run(f\"/usr/local/bin/freesasa --format=json --depth=chain {x}\", capture_output=True, shell=True)\n",
    "    free = subprocess.run(f\"/usr/local/bin/freesasa --format=json --separate-chains {x}\", capture_output=True, shell=True)\n",
    "    buried = json.loads(buried.stdout.decode())\n",
    "    free = json.loads(free.stdout.decode())\n",
    "    buried = pd.DataFrame.from_records([dict(label=x['label'], nres=x['n-residues'], **x['area']) for x in buried['results'][0]['structure'][0]['chains']])\n",
    "    free = pd.DataFrame.from_records([dict(label=x['label'], nres=x['n-residues'], **x['area']) for x in map(lambda x: x['structure'][0]['chains'][0], free['results'])])\n",
    "    all = pd.merge(buried, free, on=['label', 'nres'], suffixes=['_buried', '_free'])\n",
    "    all['total_delta'] = all['total_buried'] - all['total_free']\n",
    "    all['polar_delta'] = all['polar_buried'] - all['polar_free']\n",
    "    all['apolar_delta'] = all['apolar_buried'] - all['apolar_free']\n",
    "    return all.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complex_sasa(x):\n",
    "\n",
    "    buried = subprocess.run(f\"/usr/local/bin/freesasa --format=json --depth=structure {x}\", capture_output=True, shell=True)\n",
    "    buried = json.loads(buried.stdout.decode())\n",
    "\n",
    "    total_area =  buried['results'][0]['structure'][0]['area']['total']\n",
    "    polar_area =  buried['results'][0]['structure'][0]['area']['polar']\n",
    "    apolar_area = buried['results'][0]['structure'][0]['area']['apolar']\n",
    "\n",
    "    free = subprocess.run(f\"/usr/local/bin/freesasa --format=json --separate-chains {x}\", capture_output=True, shell=True)\n",
    "    free = json.loads(free.stdout.decode())\n",
    "    free = pd.DataFrame.from_records([dict(label=x['label'], nres=x['n-residues'], **x['area']) for x in map(lambda x: x['structure'][0]['chains'][0], free['results'])])\n",
    "    \n",
    "    total_free_area = free['total'].sum()\n",
    "    polar_free_area = free['polar'].sum()\n",
    "    apolar_free_area = free['apolar'].sum()\n",
    "\n",
    "    out = dict(\n",
    "        total_area=total_area,\n",
    "        buried_area=total_free_area - total_area,\n",
    "        polar_area=polar_area,\n",
    "        buried_polar_area=polar_free_area - polar_area,\n",
    "        apolar_area=apolar_area,\n",
    "        buried_apolar_area=apolar_free_area - apolar_area\n",
    "    )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prodigy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'nsdb-000001.clean.pdb'\n",
    "u = ['A', 'B']\n",
    "\n",
    "def prodigy_chain_interactions(x, u):\n",
    "    out = subprocess.run(f\"/home/bcz/bin/prodigy {x} --selection {u[0]} {u[1]}\", capture_output=True, shell=True)\n",
    "    y = out.stdout.decode()\n",
    "\n",
    "    return dict(\n",
    "        id = x.replace('.clean.pdb', ''),\n",
    "        interface = '_'.join(sorted(u)),\n",
    "        intermolecular_contacts  = int(re.search('No. of intermolecular contacts: (\\d*)\\n', y)[1]),\n",
    "        charged_charged_contacts = int(re.search('No. of charged-charged contacts: (\\d*)\\n', y)[1]),\n",
    "        charged_polar_contacts   = int(re.search('No. of charged-polar contacts: (\\d*)\\n', y)[1]),\n",
    "        charged_apolar_contacts  = int(re.search('No. of charged-apolar contacts: (\\d*)\\n', y)[1]),\n",
    "        apolar_polar_contacts    = int(re.search('No. of apolar-polar contacts: (\\d*)\\n', y)[1]),\n",
    "        apolar_apolar_contacts   = int(re.search('No. of apolar-apolar contacts: (\\d*)\\n', y)[1]),\n",
    "        apolar_nis_residues      = float(re.search('Percentage of apolar NIS residues: (\\d*\\.\\d*)\\n', y)[1]),\n",
    "        charged_nis_residues     = float(re.search('Percentage of charged NIS residues: (\\d*\\.\\d*)\\n', y)[1]),\n",
    "        binding_affinity         = float(re.search('Predicted binding affinity \\(kcal.mol-1\\):\\s*(\\-?\\d*\\.\\d*)\\n', y)[1])\n",
    "    )\n",
    "\n",
    "def prodigy_complex_stability(x):\n",
    "    out = subprocess.run(f\"/home/bcz/bin/prodigy {x}\", capture_output=True, shell=True)\n",
    "    y = out.stdout.decode()\n",
    "\n",
    "    return dict(\n",
    "        intermolecular_contacts  = int(re.search('No. of intermolecular contacts: (\\d*)\\n', y)[1]),\n",
    "        charged_charged_contacts = int(re.search('No. of charged-charged contacts: (\\d*)\\n', y)[1]),\n",
    "        charged_polar_contacts   = int(re.search('No. of charged-polar contacts: (\\d*)\\n', y)[1]),\n",
    "        charged_apolar_contacts  = int(re.search('No. of charged-apolar contacts: (\\d*)\\n', y)[1]),\n",
    "        apolar_polar_contacts    = int(re.search('No. of apolar-polar contacts: (\\d*)\\n', y)[1]),\n",
    "        apolar_apolar_contacts   = int(re.search('No. of apolar-apolar contacts: (\\d*)\\n', y)[1]),\n",
    "        apolar_nis_residues      = float(re.search('Percentage of apolar NIS residues: (\\d*\\.\\d*)\\n', y)[1]),\n",
    "        charged_nis_residues     = float(re.search('Percentage of charged NIS residues: (\\d*\\.\\d*)\\n', y)[1]),\n",
    "        binding_affinity         = float(re.search('Predicted binding affinity \\(kcal.mol-1\\):\\s*(\\-?\\d*\\.\\d*)\\n', y)[1])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prody as pdy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_eigvals(file):\n",
    "    x = pdy.parsePDB(file).select('name CA')\n",
    "    g = pdy.GNM()\n",
    "    g.buildKirchhoff(x)\n",
    "    g.calcModes()\n",
    "    y = g.getEigvals()\n",
    "    rad = pdy.calcGyradius(x)\n",
    "    return dict(\n",
    "        eig0=y[0], eig1=y[1], eig2=y[2], eig3=y[3], eig4=y[4], rad=rad\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_network(file):\n",
    "    ring = subprocess.run(f'/home/bcz/dev/ring-3.0.0/ring/bin/ring --best_edge -i  {file}',  capture_output=True, shell=True)\n",
    "    ring = ring.stdout.decode().splitlines()\n",
    "\n",
    "    header_edges_linenumber = ring.index('NodeId1\\tInteraction\\tNodeId2\\tDistance\\tAngle\\tEnergy\\tAtom1\\tAtom2\\tDonor\\tPositive\\tCation\\tOrientation\\tModel')\n",
    "    header_nodes_linenumber = ring.index('NodeId\\tChain\\tPosition\\tResidue\\tDssp\\tDegree\\tBfactor_CA\\tx\\ty\\tz\\tpdbFileName\\tModel')\n",
    "\n",
    "    edges = pd.read_csv(io.StringIO('\\n'.join(ring[header_edges_linenumber:header_nodes_linenumber])), sep='\\t')\n",
    "    nodes = pd.read_csv(io.StringIO('\\n'.join(ring[header_nodes_linenumber:])), sep='\\t')\n",
    "\n",
    "    nodes = nodes.rename(columns=dict(Chain='chain', Position='resid', Residue='resname'))\n",
    "    edges['Interaction'] = edges['Interaction'].apply(lambda x: x.split(':')[0])\n",
    "    nodes.NodeId = nodes.NodeId.apply(lambda x : x.replace(':_:', ':'))\n",
    "\n",
    "    g = nx.Graph()\n",
    "    nodes.query('Degree > 0').apply(lambda x: g.add_node(x.NodeId.replace(':_:', ':'), residue=x.resname, resid=x.resid, chain=x.chain), axis=1)\n",
    "    edges.apply(lambda x: g.add_edge(x.NodeId1.replace(':_:', ':'), x.NodeId2.replace(':_:', ':'), type=x.Interaction, energy=x.Energy), axis=1)\n",
    "    nodes2remove = pd.DataFrame.from_records(list(g.degree()), columns=['id', 'degree']).query('degree < 1').id.to_list()\n",
    "    g.remove_nodes_from(nodes2remove)\n",
    "    g = g.subgraph(list(sorted(nx.connected_components(g), key=len, reverse=True))[0])\n",
    "    return dict(\n",
    "        avg_shortest_path=nx.average_shortest_path_length(g),\n",
    "        avg_clustering=nx.average_clustering(g),\n",
    "        avg_density=nx.density(g),\n",
    "        avg_degree=np.mean(list(dict(g.degree()).values()))\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(x):\n",
    "    path = 'pdb/' + x + '.clean.pdb'\n",
    "    sasa = complex_sasa(path)\n",
    "    prodigy = prodigy_complex_stability(path)\n",
    "    eigvals = generate_eigvals(path)\n",
    "    network = obtain_network(path)\n",
    "    out =  dict(\n",
    "        id=x, **sasa\n",
    "    )\n",
    "    out.update(prodigy)\n",
    "    out.update(eigvals)\n",
    "    out.update(network)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = reference['id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(8)\n",
    "\n",
    "results = [\n",
    "    pool.apply_async(\n",
    "        featurize, args=(x,)\n",
    "    ) for x in targets\n",
    "]\n",
    "results = [p.get() for p in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(product['data'], 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
